{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise sheet the focus will not be on e. g. a specific classification procedure that you have to understand and train but on everything else around it. You will get to know about important aspects of the ML methodology including generating synthetic data, extracting features, splitting up the data set for training and testing as well as evaluation methods. Whenever you will implement another ML method in the upcoming days you can rely on what you learn today."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline  \n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as rng\n",
    "import matplotlib.pyplot as plt\n",
    "#import solutions\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 1: Please add the missing code in `get_data1` to draw N uniformly distributed samples from $-\\pi$ to $\\pi$.  \n",
    "Ex 2: Please add the missing code in `get_data1` and `get_data2` to add normal distributed noise with the given noise factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data1(N=1000, noise=.1):\n",
    "\n",
    "    def circle(x,radius):\n",
    "        return np.sin(x) * radius, np.cos(x) * radius\n",
    "    \n",
    "    y = rng.randint(0,2,N)\n",
    "    #print(y.shape)\n",
    "    # YOUR CODE HERE\n",
    "    X = rng.uniform(-np.pi,np.pi,N)\n",
    "    # END\n",
    "    \n",
    "    X = np.array([circle(x,radius) for x,radius in zip(X,rng.uniform(4,8,2)[y])])\n",
    "    #print(X.shape)\n",
    "    # YOUR CODE HERE\n",
    "    #X = X + np.random.normal(noise, N)\n",
    "    X += noise * rng.randn(*X.shape)\n",
    "    # END\n",
    "    #print(X.shape)\n",
    "    \n",
    "    # translate\n",
    "    X[:,0] += noise * rng.uniform(0,10)\n",
    "    X[:,1] += noise * rng.uniform(0,10)\n",
    "    #print(y.shape)\n",
    "    return X,y\n",
    "\n",
    "\n",
    "def get_data2(N=1000, noise=.5):\n",
    "    \n",
    "    y = rng.randint(0,2,N)\n",
    "    X = np.linspace(0, 6, N)\n",
    "    \n",
    "    def desc(x):\n",
    "        return x, -x + 6\n",
    "    \n",
    "    def asc(x):\n",
    "        return x,x\n",
    "    \n",
    "    X = np.array([asc(x) if yc == 1 else desc(x) for x,yc in zip(X, y)])\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    X += noise * rng.randn(*X.shape)\n",
    "    # END\n",
    "    \n",
    "    # translate\n",
    "    X[:,0] += noise * rng.uniform(0,10)\n",
    "    X[:,1] += noise * rng.uniform(0,10)\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1,y1 = get_data1(noise=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2,y2 = get_data2(noise=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ex 3: create a scatterplot of the X values and color the points according to their y value. Please make sure that both axes have the same scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(X,y):\n",
    "    # YOUR CODE HERE\n",
    "    plt.scatter(X[:,0],X[:,1],c=y)\n",
    "    plt.axis('equal')\n",
    "    # END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X2,y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX4: Center the given data around zero.  \n",
    "EX5: With the knowledge you have about the structure of the data, create a custom one dimensional feature representation in that the classes are lineary separable  \n",
    "EX6: With the knowledge you have about the structure of the data, create a custom two dimensional feature representation in that the classes are lineary separable  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_basic(X):\n",
    "    # YOUR CODE HERE\n",
    "    X[:,0] = X[:,0] - np.mean(X[:,0])\n",
    "    X[:,1] = X[:,1] - np.mean(X[:,1])\n",
    "    return X\n",
    "    # END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features1(X):\n",
    "    # YOUR CODE HERE\n",
    "    X = extract_features_basic(X)\n",
    "    X = np.sqrt(X[:,0]**2+X[:,1]**2)\n",
    "    return X\n",
    "    # END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features2(X):\n",
    "    # YOUR CODE HERE\n",
    "    X = extract_features_basic(X)\n",
    "    #print(X)\n",
    "    X[:,0] = X[:,0] * X[:,1]\n",
    "    #print(X)\n",
    "    zeroes = np.zeros(X.shape)\n",
    "    zeroes[:,0] = X[:,0]\n",
    "    print(zeroes)\n",
    "    return zeroes\n",
    "    # END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_feat = extract_features1(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.plot(X1_feat, y1, \"o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_feat = extract_features2(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(X2_feat, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX7: Implement the `train_test_split` function that splits `X` and `y` in two parts of `test_portion` ratio. Whether the samples should be shuffled depends on `perform_shuffle`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_portion=.25, perform_shuffle=True):\n",
    "    # YOUR CODE HERE\n",
    "    if(perform_shuffle):\n",
    "        c = list(zip(X, y))\n",
    "        rng.shuffle(c)\n",
    "        X, y = zip(*c)\n",
    "    X_train, X_test, X_val = np.split(X, [int((1-test_portion) * len(X)), int(1 * len(X))])\n",
    "    y_train, y_test, y_val = np.split(y, [int((1-test_portion) * len(y)), int(1 * len(y))])\n",
    "\n",
    "    return X_train, y_train, X_test, y_test\n",
    "    # END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, y1_train, X1_test, y1_test = train_test_split(X1_feat, y1)\n",
    "X2_train, y2_train, X2_test, y2_test = train_test_split(X2_feat, y2)\n",
    "print(X1_train.shape)\n",
    "print(y1_train.shape)\n",
    "print(X1_test.shape)\n",
    "print(y1_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following two cells a classifier is given. In this exercise you should not worry about how the classifier works, just note that the predictions of the different X splits are stored in `train_prediction1`, `test_prediction1` (first data set), `train_prediction2`, `test_prediction2` (second data set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression()\n",
    "clf1.fit(X1_train.reshape(len(X1_train), 1), y1_train)\n",
    "train_prediction1 = clf1.predict(X1_train.reshape(len(X1_train), 1))\n",
    "test_prediction1 = clf1.predict(X1_test.reshape(len(X1_test), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = LogisticRegression()\n",
    "clf2.fit(X2_train.reshape(len(X2_train), 2), y2_train)\n",
    "train_prediction2 = clf2.predict(X2_train.reshape(len(X2_train), 2))\n",
    "test_prediction2 = clf2.predict(X2_test.reshape(len(X2_test), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX8: please compute the four evaluation methods \n",
    "    1. precision\n",
    "    2. recall\n",
    "    3. accuracy\n",
    "    4. f1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_pred, y_true):\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    false_neg = 0\n",
    "    true_neg = 0\n",
    "    #print(len(y_pred))\n",
    "    for i,j in zip(y_pred,y_true):\n",
    "        if i == 1 and j == 1:\n",
    "            true_pos += 1\n",
    "        elif i==1 and j == 0:\n",
    "            false_pos += 1\n",
    "        elif i==0 and i == 1:\n",
    "            false_neg += 1\n",
    "        else:\n",
    "            true_neg += 1\n",
    "        \n",
    "    #print(true_pos)\n",
    "    #print(y_pred.sum())\n",
    "    #print(y_true.sum())\n",
    "    #print(y_pred, y_true)\n",
    "    # YOUR CODE HERE\n",
    "    precision = true_pos/(true_pos+false_pos)\n",
    "    recall = true_pos/(true_pos + false_neg)\n",
    "    accuracy = (true_pos + true_neg)/len(y_pred)\n",
    "    print(\"precision=\", precision)\n",
    "    print(\"recall=\", recall)\n",
    "    print(\"accuracy=\",accuracy)\n",
    "    print(\"f1=\", 2 * ((precision * recall)/(precision + recall)))\n",
    "    # END\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_prediction1, y1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX9: Plot the test set `X1_test` as histogram and visualize the decision boundary of the classifier `clf1`. Hint: You can use `clf1.predict(...)` to generate new output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "_ = plt.hist(X1_test)\n",
    "\n",
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(test_prediction2, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX10: Plot the X2_test as a scatter plot and visualize the decision boundary of `clf2` as a contour. Hint: `plt.contourf(...)` can be used to plot a contour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "plot_data(X2_test, y2_test)\n",
    "# END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EX11: Interpret the output of the following cell with regard to the concept of generalization. Point out the crucial parts that have an effect on generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_feat = extract_features_basic(X2)\n",
    "\n",
    "X2_train, y2_train, X2_test, y2_test = train_test_split(X2_feat, y2, test_portion=.5, perform_shuffle=False)\n",
    "\n",
    "clf3 = LogisticRegression()\n",
    "clf3.fit(X2_train.reshape(len(X2_train), 2), y2_train)\n",
    "train_prediction2 = clf3.predict(X2_train.reshape(len(X2_train), 2))\n",
    "test_prediction2 = clf3.predict(X2_test.reshape(len(X2_test), 2))\n",
    "\n",
    "print(\"training performance\")\n",
    "evaluate(train_prediction2, y2_train)\n",
    "print(\"test performance\")\n",
    "evaluate(test_prediction2, y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It poorly generalize on the badly separated dataset, where 50% was used for training and 50% for testing without even shuffeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
